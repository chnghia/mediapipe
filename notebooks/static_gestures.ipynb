{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spiritual-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sharp-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '../myMediaPipe/trainingData/210316_1115'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accompanied-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: ../myMediaPipe/trainingData/210316_1115: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls $dataPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsFile = os.path.join(dataPath, \"labels.csv\")\n",
    "labels = pd.read_csv(labelsFile,header=None)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "preData  = {}\n",
    "for label in labels.itertuples():\n",
    "    trainingFile = os.path.join(dataPath,label[2] + \".csv\")\n",
    "    preData[label.Index] = pd.read_csv(trainingFile,header=None)\n",
    "    print(\"Loading file:\", trainingFile, \"\\tNumber of Rows:\" , len(preData[label.Index].index))\n",
    "    print(label.Index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "for key in preData.keys():\n",
    "    print(\"Record #:\", key, \"\\thas:\",len(preData[key].index) % 21, \"incomplete captures\")\n",
    "    preData[key].drop(preData[key].tail(len(preData[key].index) % 21).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance data\n",
    "recordsPerClass = len(preData[0].index) #initial value\n",
    "#Calculate smallest class\n",
    "for key in preData.keys():\n",
    "    if recordsPerClass > len(preData[key].index): \n",
    "        recordsPerClass=len(preData[key].index)\n",
    "    #print(recordsPerClass)\n",
    "\n",
    "#Trimming\n",
    "for key in preData.keys():\n",
    "    preData[key] = preData[key].head(recordsPerClass)\n",
    "    print(len(preData[key].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds training and label array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrainRows, numTestRows = 0,0\n",
    "numLandmaks = 21\n",
    "numCols = numLandmaks*2\n",
    "\n",
    "\n",
    "def countRows(dataDict):\n",
    "    rowsCount=0\n",
    "    for key in dataDict.keys():\n",
    "        rowsCount += len(dataDict[key].index)\n",
    "    return rowsCount\n",
    "\n",
    "numRows = countRows(preData)\n",
    "#numTestRows = countRows(testData)\n",
    "\n",
    "numTransRows = int(numRows / numLandmaks)\n",
    "transData = np.zeros((numTransRows,numCols),preData[1][4].dtypes)\n",
    "transLabels = np.zeros((numTransRows),np.int16)\n",
    "\n",
    "#numTestRows = int(numTestRows / numLandmaks)\n",
    "#testingData = np.zeros((numTestRows,numCols),preData[1][4].dtypes)\n",
    "#testingLabels = np.zeros((numTestRows),np.int16)\n",
    "\n",
    "print(\"Number of Rows in total:\", numTransRows)  \n",
    "print(transData.shape, transData.dtype)\n",
    "print(transLabels.shape, transLabels.dtype)\n",
    "\n",
    "#print(testingData.shape, testingData.dtype)\n",
    "#print(testingLabels.shape, testingLabels.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposeInterleave(a, b):\n",
    "    c = np.empty((a.size + b.size,), dtype=a.dtype)\n",
    "    c[0::2] = a\n",
    "    c[1::2] = b\n",
    "    return c\n",
    "\n",
    "def dataTransp(dataDict,processedData,processedLabels):\n",
    "    j = 0\n",
    "    for key in dataDict.keys():\n",
    "        for i in range(0, len(dataDict[key].index), numLandmaks):  \n",
    "            #print(dataDict[1].iloc[i : i + numLandmaks,3:5])\n",
    "            a= np.ravel(np.asarray(dataDict[key].iloc[i : i + numLandmaks,3:4]))\n",
    "            b= np.ravel(np.asarray(dataDict[key].iloc[i : i + numLandmaks,4:5]))\n",
    "            #print(\"j:\",j)\n",
    "            processedData[j] = transposeInterleave(a,b)\n",
    "            processedLabels[j] =labels.iloc[key,2]\n",
    "            j+=1\n",
    "     # retun True\n",
    "\n",
    "dataTransp(preData,transData,transLabels) \n",
    "\n",
    "print(transData[-1])\n",
    "print(transLabels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels to one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "print(transLabels.shape)\n",
    "transLabels = to_categorical(transLabels)\n",
    "print(transLabels.shape)\n",
    "print(transLabels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set apart Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "testDataRatio= 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transData,transLabels, test_size=testDataRatio)\n",
    "print( \"\\tTraining records:\", np.shape(X_train)[0], \"\\tTest records:\", np.shape(X_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(numCols,)))\n",
    "model.add(layers.Dense(42, activation='relu'))\n",
    "model.add(layers.Dense(len(labels.index), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=40,\n",
    "                    #batch_size=512,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'go', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('\\nTesting loss: {}%, acc: {}%\\n'.format(round(loss*100,2),round(acc*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "model.save('gestures002.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file( 'gestures001.h5') \n",
    "liteModel = converter.convert()\n",
    "\n",
    "open(\"gestures002.tflite\", \"wb\").write(liteModel)\n",
    "\n",
    "#file = open( 'gestures001.tflite' , 'wb' ) \n",
    "#file.write( liteModel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-roommate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-treasurer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
